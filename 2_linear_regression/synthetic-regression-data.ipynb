{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "608018c8",
      "metadata": {
        "id": "608018c8"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "91b3a9ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91b3a9ef",
        "outputId": "67fa9fc2-2b7d-4f76-b583-c28c84dbd60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l==1.0.3 in /usr/local/lib/python3.12/dist-packages (1.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install d2l==1.0.3 --no-deps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d13df7ea",
      "metadata": {
        "origin_pos": 1,
        "id": "d13df7ea"
      },
      "source": [
        "# Synthetic Regression Data\n",
        ":label:`sec_synthetic-regression-data`\n",
        "\n",
        "\n",
        "Machine learning is all about extracting information from data.\n",
        "So you might wonder, what could we possibly learn from synthetic data?\n",
        "While we might not care intrinsically about the patterns\n",
        "that we ourselves baked into an artificial data generating model,\n",
        "such datasets are nevertheless useful for didactic purposes,\n",
        "helping us to evaluate the properties of our learning\n",
        "algorithms and to confirm that our implementations work as expected.\n",
        "For example, if we create data for which the correct parameters are known *a priori*,\n",
        "then we can check that our model can in fact recover them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b9773b7e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:11.561594Z",
          "iopub.status.busy": "2023-08-18T19:36:11.560983Z",
          "iopub.status.idle": "2023-08-18T19:36:15.344149Z",
          "shell.execute_reply": "2023-08-18T19:36:15.342706Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "b9773b7e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b65a3a2",
      "metadata": {
        "origin_pos": 6,
        "id": "4b65a3a2"
      },
      "source": [
        "## Generating the Dataset\n",
        "\n",
        "For this example, we will work in low dimension\n",
        "for succinctness.\n",
        "The following code snippet generates 1000 examples\n",
        "with 2-dimensional features drawn\n",
        "from a standard normal distribution.\n",
        "The resulting design matrix $\\mathbf{X}$\n",
        "belongs to $\\mathbb{R}^{1000 \\times 2}$.\n",
        "We generate each label by applying\n",
        "a *ground truth* linear function,\n",
        "corrupting them via additive noise $\\boldsymbol{\\epsilon}$,\n",
        "drawn independently and identically for each example:\n",
        "\n",
        "(**$$\\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\boldsymbol{\\epsilon}.$$**)\n",
        "\n",
        "For convenience we assume that $\\boldsymbol{\\epsilon}$ is drawn\n",
        "from a normal distribution with mean $\\mu= 0$\n",
        "and standard deviation $\\sigma = 0.01$.\n",
        "Note that for object-oriented design\n",
        "we add the code to the `__init__` method of a subclass of `d2l.DataModule` (introduced in :numref:`oo-design-data`).\n",
        "It is good practice to allow the setting of any additional hyperparameters.\n",
        "We accomplish this with `save_hyperparameters()`.\n",
        "The `batch_size` will be determined later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e174e8b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.351059Z",
          "iopub.status.busy": "2023-08-18T19:36:15.350010Z",
          "iopub.status.idle": "2023-08-18T19:36:15.358156Z",
          "shell.execute_reply": "2023-08-18T19:36:15.357035Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "e174e8b1"
      },
      "outputs": [],
      "source": [
        "class SyntheticRegressionData(d2l.DataModule):  #@save\n",
        "    \"\"\"Synthetic data for linear regression.\"\"\"\n",
        "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n",
        "                 batch_size=32):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        n = num_train + num_val\n",
        "        self.X = torch.randn(n, len(w))\n",
        "        noise = torch.randn(n, 1) * noise\n",
        "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60afd383",
      "metadata": {
        "origin_pos": 8,
        "id": "60afd383"
      },
      "source": [
        "Below, we set the true parameters to $\\mathbf{w} = [2, -3.4]^\\top$ and $b = 4.2$.\n",
        "Later, we can check our estimated parameters against these *ground truth* values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "38a83404",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.362285Z",
          "iopub.status.busy": "2023-08-18T19:36:15.361503Z",
          "iopub.status.idle": "2023-08-18T19:36:15.390526Z",
          "shell.execute_reply": "2023-08-18T19:36:15.389339Z"
        },
        "origin_pos": 9,
        "tab": [
          "pytorch"
        ],
        "id": "38a83404"
      },
      "outputs": [],
      "source": [
        "data = SyntheticRegressionData(w=torch.tensor([2, -3.4]), b=4.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4105d024",
      "metadata": {
        "origin_pos": 10,
        "id": "4105d024"
      },
      "source": [
        "[**Each row in `features` consists of a vector in $\\mathbb{R}^2$ and each row in `labels` is a scalar.**] Let's have a look at the first entry.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "43e267cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.395708Z",
          "iopub.status.busy": "2023-08-18T19:36:15.394509Z",
          "iopub.status.idle": "2023-08-18T19:36:15.405078Z",
          "shell.execute_reply": "2023-08-18T19:36:15.402629Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43e267cb",
        "outputId": "28c2fc00-a6a5-4431-973a-a25df43426e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: tensor([-1.9250,  0.2228]) \n",
            "label: tensor([-0.4217])\n"
          ]
        }
      ],
      "source": [
        "print('features:', data.X[0],'\\nlabel:', data.y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf8516d3",
      "metadata": {
        "origin_pos": 12,
        "id": "bf8516d3"
      },
      "source": [
        "## Reading the Dataset\n",
        "\n",
        "Training machine learning models often requires multiple passes over a dataset,\n",
        "grabbing one minibatch of examples at a time.\n",
        "This data is then used to update the model.\n",
        "To illustrate how this works, we\n",
        "[**implement the `get_dataloader` method,**]\n",
        "registering it in the `SyntheticRegressionData` class via `add_to_class` (introduced in :numref:`oo-design-utilities`).\n",
        "It (**takes a batch size, a matrix of features,\n",
        "and a vector of labels, and generates minibatches of size `batch_size`.**)\n",
        "As such, each minibatch consists of a tuple of features and labels.\n",
        "Note that we need to be mindful of whether we're in training or validation mode:\n",
        "in the former, we will want to read the data in random order,\n",
        "whereas for the latter, being able to read data in a pre-defined order\n",
        "may be important for debugging purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1686e6b2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.409740Z",
          "iopub.status.busy": "2023-08-18T19:36:15.408327Z",
          "iopub.status.idle": "2023-08-18T19:36:15.417911Z",
          "shell.execute_reply": "2023-08-18T19:36:15.416944Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "1686e6b2"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(SyntheticRegressionData)\n",
        "def get_dataloader(self, train):\n",
        "    if train:\n",
        "        indices = list(range(0, self.num_train))\n",
        "        # The examples are read in random order\n",
        "        random.shuffle(indices)\n",
        "    else:\n",
        "        indices = list(range(self.num_train, self.num_train+self.num_val))\n",
        "    for i in range(0, len(indices), self.batch_size):\n",
        "        batch_indices = torch.tensor(indices[i: i+self.batch_size])\n",
        "        yield self.X[batch_indices], self.y[batch_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2437653f",
      "metadata": {
        "origin_pos": 14,
        "id": "2437653f"
      },
      "source": [
        "To build some intuition, let's inspect the first minibatch of\n",
        "data. Each minibatch of features provides us with both its size and the dimensionality of input features.\n",
        "Likewise, our minibatch of labels will have a matching shape given by `batch_size`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d5af1472",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.424253Z",
          "iopub.status.busy": "2023-08-18T19:36:15.423639Z",
          "iopub.status.idle": "2023-08-18T19:36:15.430119Z",
          "shell.execute_reply": "2023-08-18T19:36:15.429099Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5af1472",
        "outputId": "006816a1-4a88-43a9-a2ff-769bf0dd1575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([32, 2]) \n",
            "y shape: torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(data.train_dataloader()))\n",
        "print('X shape:', X.shape, '\\ny shape:', y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c485f93e",
      "metadata": {
        "origin_pos": 16,
        "id": "c485f93e"
      },
      "source": [
        "While seemingly innocuous, the invocation\n",
        "of `iter(data.train_dataloader())`\n",
        "illustrates the power of Python's object-oriented design.\n",
        "Note that we added a method to the `SyntheticRegressionData` class\n",
        "*after* creating the `data` object.\n",
        "Nonetheless, the object benefits from\n",
        "the *ex post facto* addition of functionality to the class.\n",
        "\n",
        "Throughout the iteration we obtain distinct minibatches\n",
        "until the entire dataset has been exhausted (try this).\n",
        "While the iteration implemented above is good for didactic purposes,\n",
        "it is inefficient in ways that might get us into trouble with real problems.\n",
        "For example, it requires that we load all the data in memory\n",
        "and that we perform lots of random memory access.\n",
        "The built-in iterators implemented in a deep learning framework\n",
        "are considerably more efficient and they can deal\n",
        "with sources such as data stored in files,\n",
        "data received via a stream,\n",
        "and data generated or processed on the fly.\n",
        "Next let's try to implement the same method using built-in iterators.\n",
        "\n",
        "## Concise Implementation of the Data Loader\n",
        "\n",
        "Rather than writing our own iterator,\n",
        "we can [**call the existing API in a framework to load data.**]\n",
        "As before, we need a dataset with features `X` and labels `y`.\n",
        "Beyond that, we set `batch_size` in the built-in data loader\n",
        "and let it take care of shuffling examples  efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d5ae674e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.434272Z",
          "iopub.status.busy": "2023-08-18T19:36:15.433429Z",
          "iopub.status.idle": "2023-08-18T19:36:15.441792Z",
          "shell.execute_reply": "2023-08-18T19:36:15.439267Z"
        },
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "id": "d5ae674e"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(d2l.DataModule)  #@save\n",
        "def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
        "    tensors = tuple(a[indices] for a in tensors)\n",
        "    dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "    return torch.utils.data.DataLoader(dataset, self.batch_size,\n",
        "                                       shuffle=train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "617242ed",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.448335Z",
          "iopub.status.busy": "2023-08-18T19:36:15.447832Z",
          "iopub.status.idle": "2023-08-18T19:36:15.457888Z",
          "shell.execute_reply": "2023-08-18T19:36:15.456920Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "617242ed"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(SyntheticRegressionData)  #@save\n",
        "def get_dataloader(self, train):\n",
        "    i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
        "    return self.get_tensorloader((self.X, self.y), train, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b36d404",
      "metadata": {
        "origin_pos": 20,
        "id": "9b36d404"
      },
      "source": [
        "The new data loader behaves just like the previous one, except that it is more efficient and has some added functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2f5d57c3",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "4"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.464003Z",
          "iopub.status.busy": "2023-08-18T19:36:15.462740Z",
          "iopub.status.idle": "2023-08-18T19:36:15.474793Z",
          "shell.execute_reply": "2023-08-18T19:36:15.473623Z"
        },
        "origin_pos": 21,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f5d57c3",
        "outputId": "05b58c62-a61a-465d-9f1f-a27383bc6b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([32, 2]) \n",
            "y shape: torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(data.train_dataloader()))\n",
        "print('X shape:', X.shape, '\\ny shape:', y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e8e09f0",
      "metadata": {
        "origin_pos": 22,
        "id": "4e8e09f0"
      },
      "source": [
        "For instance, the data loader provided by the framework API\n",
        "supports the built-in `__len__` method,\n",
        "so we can query its length,\n",
        "i.e., the number of batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "790cbdfb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:36:15.479797Z",
          "iopub.status.busy": "2023-08-18T19:36:15.478884Z",
          "iopub.status.idle": "2023-08-18T19:36:15.489245Z",
          "shell.execute_reply": "2023-08-18T19:36:15.488320Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "790cbdfb",
        "outputId": "d8fe4809-d10a-421a-de8d-fb05359983dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "len(data.train_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e73e34",
      "metadata": {
        "origin_pos": 24,
        "id": "d5e73e34"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Data loaders are a convenient way of abstracting out\n",
        "the process of loading and manipulating data.\n",
        "This way the same machine learning *algorithm*\n",
        "is capable of processing many different types and sources of data\n",
        "without the need for modification.\n",
        "One of the nice things about data loaders\n",
        "is that they can be composed.\n",
        "For instance, we might be loading images\n",
        "and then have a postprocessing filter\n",
        "that crops them or modifies them in other ways.\n",
        "As such, data loaders can be used\n",
        "to describe an entire data processing pipeline.\n",
        "\n",
        "As for the model itself, the two-dimensional linear model\n",
        "is about the simplest we might encounter.\n",
        "It lets us test out the accuracy of regression models\n",
        "without worrying about having insufficient amounts of data\n",
        "or an underdetermined system of equations.\n",
        "We will put this to good use in the next section.  \n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. What will happen if the number of examples cannot be divided by the batch size. How would you change this behavior by specifying a different argument by using the framework's API?\n",
        "1. Suppose that we want to generate a huge dataset, where both the size of the parameter vector `w` and the number of examples `num_examples` are large.\n",
        "    1. What happens if we cannot hold all data in memory?\n",
        "    1. How would you shuffle the data if it is held on disk? Your task is to design an *efficient* algorithm that does not require too many random reads or writes. Hint: [pseudorandom permutation generators](https://en.wikipedia.org/wiki/Pseudorandom_permutation) allow you to design a reshuffle without the need to store the permutation table explicitly :cite:`Naor.Reingold.1999`.\n",
        "1. Implement a data generator that produces new data on the fly, every time the iterator is called.\n",
        "1. How would you design a random data generator that generates *the same* data each time it is called?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1."
      ],
      "metadata": {
        "id": "GRvBXGIGcYqd"
      },
      "id": "GRvBXGIGcYqd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ccbd0c",
        "outputId": "fbae0a3c-26ba-429a-8e01-7063b8b017b7"
      },
      "source": [
        "# Create a dataset with 10 examples\n",
        "X = torch.randn(10, 2)\n",
        "y = torch.randn(10, 1)\n",
        "\n",
        "# Create a DataLoader with batch size 3 and drop_last=False (default)\n",
        "dataset = torch.utils.data.TensorDataset(X, y)\n",
        "dataloader_no_drop = torch.utils.data.DataLoader(dataset, batch_size=3, shuffle=False, drop_last=False)\n",
        "\n",
        "print(\"DataLoader with drop_last=False:\")\n",
        "for i, (X_batch, y_batch) in enumerate(dataloader_no_drop):\n",
        "    print(f\"Batch {i+1}: X shape {X_batch.shape}, y shape {y_batch.shape}\")\n",
        "\n",
        "# Create a DataLoader with batch size 3 and drop_last=True\n",
        "dataloader_drop = torch.utils.data.DataLoader(dataset, batch_size=3, shuffle=False, drop_last=True)\n",
        "\n",
        "print(\"\\nDataLoader with drop_last=True:\")\n",
        "for i, (X_batch, y_batch) in enumerate(dataloader_drop):\n",
        "    print(f\"Batch {i+1}: X shape {X_batch.shape}, y shape {y_batch.shape}\")"
      ],
      "id": "21ccbd0c",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoader with drop_last=False:\n",
            "Batch 1: X shape torch.Size([3, 2]), y shape torch.Size([3, 1])\n",
            "Batch 2: X shape torch.Size([3, 2]), y shape torch.Size([3, 1])\n",
            "Batch 3: X shape torch.Size([3, 2]), y shape torch.Size([3, 1])\n",
            "Batch 4: X shape torch.Size([1, 2]), y shape torch.Size([1, 1])\n",
            "\n",
            "DataLoader with drop_last=True:\n",
            "Batch 1: X shape torch.Size([3, 2]), y shape torch.Size([3, 1])\n",
            "Batch 2: X shape torch.Size([3, 2]), y shape torch.Size([3, 1])\n",
            "Batch 3: X shape torch.Size([3, 2]), y shape torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6d8f2c",
      "metadata": {
        "origin_pos": 26,
        "tab": [
          "pytorch"
        ],
        "id": "3a6d8f2c"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/6663)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc0c79c9"
      },
      "source": [
        "### How would you shuffle the data if it is held on disk?\n",
        "\n",
        "Shuffling data that is too large to fit in memory requires a strategy that minimizes random access to the disk, as this is a slow operation. Traditional shuffling methods that involve loading the entire dataset into memory and then randomly reordering it are not feasible.\n",
        "\n",
        "An efficient approach for shuffling large datasets on disk involves using techniques that can generate a permutation of the data without explicitly storing the entire permutation in memory. One way to achieve this is by using **pseudorandom permutation generators**.\n",
        "\n",
        "A pseudorandom permutation generator can generate a deterministic permutation of a sequence based on a key. This means that given the same key, it will always produce the same permutation. For shuffling a large dataset on disk, you can:\n",
        "\n",
        "1.  Generate a sequence of indices from 0 to the number of examples in your dataset.\n",
        "2.  Use a pseudorandom permutation generator with a chosen key to generate a shuffled sequence of these indices.\n",
        "3.  When reading data, instead of reading sequentially, read the examples according to the shuffled sequence of indices.\n",
        "\n",
        "This approach avoids loading the entire dataset into memory and minimizes random reads by accessing data in a determined (though shuffled) order. You can process the data in chunks based on the shuffled indices.\n",
        "\n",
        "Libraries or frameworks for handling large datasets often implement efficient shuffling strategies like this internally within their data loading utilities."
      ],
      "id": "cc0c79c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa989f76"
      },
      "source": [
        "### What happens if we cannot hold all data in memory?\n",
        "\n",
        "When a dataset is too large to fit into your computer's RAM, attempting to load it all at once will result in an out-of-memory error. This means traditional methods of loading the entire dataset into a data structure like a pandas DataFrame or a PyTorch Tensor are not feasible.\n",
        "\n",
        "Instead, you need to process the data in smaller chunks that *can* fit into memory. This often involves reading data directly from disk, processing a batch, and then discarding it before reading the next batch. This approach is common in deep learning, where data loaders are designed to handle large datasets by loading data in mini-batches.\n",
        "\n",
        "However, this also introduces challenges for operations that require access to the entire dataset, such as shuffling."
      ],
      "id": "fa989f76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0255e06"
      },
      "source": [
        "## 3. Implement a data generator that produces new data on the fly\n",
        "\n",
        "### Subtask:\n",
        "Implement a data generator that produces new data on the fly.\n"
      ],
      "id": "c0255e06"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a054762"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `OnTheFlyDataGenerator` class as described in the instructions, including the `__init__` method and the `get_dataloader` method with the nested `data_iter` generator function.\n",
        "\n"
      ],
      "id": "1a054762"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8f2ff75"
      },
      "source": [
        "class OnTheFlyDataGenerator(d2l.DataModule):\n",
        "    \"\"\"Synthetic data generator that produces data on the fly.\"\"\"\n",
        "    def __init__(self, w, b, noise=0.01, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def get_dataloader(self, train):\n",
        "        # train parameter is not used as data is generated infinitely\n",
        "        def data_iter():\n",
        "            while True:\n",
        "                X = torch.randn(self.batch_size, len(self.w))\n",
        "                noise = torch.randn(self.batch_size, 1) * self.noise\n",
        "                y = torch.matmul(X, self.w.reshape((-1, 1))) + self.b + noise\n",
        "                yield X, y\n",
        "        return data_iter()"
      ],
      "id": "b8f2ff75",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "247cd76e"
      },
      "source": [
        "## 4. Implement a data generator that generates the same data each time\n",
        "\n",
        "### Subtask:\n",
        "Implement a data generator that generates the same data each time it is called.\n"
      ],
      "id": "247cd76e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b709158f"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `ReproducibleDataGenerator` class as described in the instructions, including setting the random seed and generating the data in the constructor.\n",
        "\n"
      ],
      "id": "b709158f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "285d1521"
      },
      "source": [
        "class ReproducibleDataGenerator(d2l.DataModule):\n",
        "    \"\"\"Synthetic data generator that produces the same data each time.\"\"\"\n",
        "    def __init__(self, w, b, noise=0.01, num_examples=1000, batch_size=32, seed=42):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        torch.manual_seed(seed)\n",
        "        self.X = torch.randn(num_examples, len(w))\n",
        "        noise = torch.randn(num_examples, 1) * noise\n",
        "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise\n",
        "\n",
        "    def get_dataloader(self, train):\n",
        "        dataset = torch.utils.data.TensorDataset(self.X, self.y)\n",
        "        return torch.utils.data.DataLoader(dataset, self.batch_size,\n",
        "                                       shuffle=train)"
      ],
      "id": "285d1521",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18ac5ae7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   A data generator that produces new data on the fly can be implemented by yielding newly generated data within an infinite loop in the `data_iter` function.\n",
        "*   A data generator that produces the same data each time can be implemented by setting a random seed using `torch.manual_seed()` before generating the entire dataset (`X` and `y`) within the `__init__` method.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Setting a random seed is crucial for ensuring reproducibility in data generation and experiments.\n",
        "*   Choosing between generating data on the fly or generating it once depends on the dataset size, memory constraints, and the need for data variability during training.\n"
      ],
      "id": "18ac5ae7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}